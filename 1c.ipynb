{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not much comments here, feel free to contact @ fb.com/noallynoclan\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "DUMP_DIR = os.path.join(os.getcwd(), 'dump')\n",
    "BLOCK = 'date_block_num'\n",
    "TARGET = 'item_cnt_month'\n",
    "INDEX_COLS = ['date_block_num', 'shop_id', 'item_id']\n",
    "VAL_COLS = ['item_price', 'item_cnt_month']\n",
    "DROP_COLS = ['ID', 'item_category_id']\n",
    "\n",
    "def proc(df): # downsizes to 32b\n",
    "    pref_ord = ['ID', *INDEX_COLS, 'item_price', 'item_cnt_month']\n",
    "    cols_ord = [*[c for c in pref_ord if c in df], *[c for c in df if c not in pref_ord]]\n",
    "    for col in df:\n",
    "        if df[col].dtype not in ('int32', 'object'):\n",
    "            if not df[col].isnull().sum():\n",
    "                col_int32 = df[col].astype(np.int32)\n",
    "                if np.allclose(df[col], col_int32): df[col] = col_int32\n",
    "        if df[col].dtype == 'float64': df[col] = df[col].astype(np.float32)\n",
    "    gc.collect()\n",
    "    return df.reindex(columns=cols_ord)\n",
    "\n",
    "def describe(df): # prints shape, size, nulls, object & 64b cols\n",
    "    cols = {'NULLS': [], 'O': [], 'N64': [], 'N32': []}\n",
    "    for col in df:\n",
    "        nulls = df[col].isnull().sum()\n",
    "        if nulls: cols['NULLS'].append((col, nulls))\n",
    "        if df[col].dtype in ('int32', 'float32'): cols['N32'].append(col)\n",
    "        elif df[col].dtype in ('int64', 'float64'): cols['N64'].append(col)\n",
    "        elif df[col].dtype  == 'object': cols['O'].append(col)\n",
    "    print(df.shape, int(sys.getsizeof(df) / 1_000_000), end='MB, ')\n",
    "    print({dtype: cols[dtype] for dtype in ['NULLS', 'O', 'N64'] if cols[dtype]})\n",
    "    return df[::int(len(df)/3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA\n",
    "def read(file): # reads, filters columns\n",
    "    print(file, end=' ')\n",
    "    drop_cols = {'item_category_name', 'item_name', 'date', 'shop_name'}\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, file + '.csv'))\n",
    "    df = df.drop(drop_cols.intersection(df.columns), axis=1)\n",
    "    df = proc(df)\n",
    "    describe(df) \n",
    "    return df\n",
    "\n",
    "data = {f: read(f) for f in ['item_categories', 'items', 'sales_train', 'shops', 'test']}\n",
    "price_lim = data['sales_train']['item_price'].quantile(0.999)\n",
    "data['sales_train']['item_price'] = np.minimum(data['sales_train']['item_price'], price_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPROCESSING\n",
    "# MERGE DATA INTO GRID\n",
    "data['train'] = (data['sales_train'].groupby(INDEX_COLS, as_index=False)\n",
    "                 .agg({'item_price': np.mean, 'item_cnt_day': np.sum})\n",
    "                 .rename(columns={'item_cnt_day': 'item_cnt_month'}))\n",
    "data['test'][BLOCK] = 34\n",
    "df = proc(pd.concat([data['train'], data['test']]))\n",
    "grid = [] \n",
    "for block in df[BLOCK].unique():\n",
    "    shops = df[df[BLOCK] == block]['shop_id'].unique()\n",
    "    items = df[df[BLOCK] == block]['item_id'].unique()\n",
    "    grid.append(np.array(list(itertools.product(*[[block], shops, items])), dtype=np.int32))\n",
    "grid = pd.DataFrame(np.vstack(grid), columns=INDEX_COLS, dtype=np.int32)\n",
    "df = grid.merge(df, how='left', on=INDEX_COLS)\n",
    "\n",
    "# ADDITION INFO\n",
    "df['item_cnt_month'] = np.clip(df['item_cnt_month'].fillna(0), 0, 20)\n",
    "df['ID'] = df['ID'].fillna(-1).astype(np.int32)\n",
    "df = df.merge(data['items'], how='left', on='item_id')\n",
    "df['year'] = 2013 + df[BLOCK] // 12\n",
    "df['month'] = df[BLOCK] % 12 + 1\n",
    "df = proc(df).sort_values(INDEX_COLS)\n",
    "\n",
    "# ADD LAGS\n",
    "for lag in [1, 2, 3, 6, 12]:\n",
    "    print('lagging:', lag)\n",
    "    lagged = df[INDEX_COLS + VAL_COLS].copy()\n",
    "    lagged[BLOCK] += lag\n",
    "    df = df.merge(lagged, how='left', on=INDEX_COLS, suffixes=('', '_{}_lag'.format(lag)))\n",
    "\n",
    "# ADD ENCODINGS\n",
    "def encode(df, block, encs, vals): # big mess here\n",
    "    _ = lambda cols: ['_' + col for col in cols]\n",
    "    cols = set(sum(vals.values(), []))\n",
    "    for col in cols:\n",
    "        df['_' + col] = df[col].notnull()\n",
    "    pivot = df.groupby([block, *encs])[[*cols, *_(cols)]].sum()\n",
    "    df = df.drop(_(cols), axis=1)\n",
    "    if 'mean' in vals:\n",
    "        mean_vals = [*vals['mean'], *_(vals['mean'])]\n",
    "        enc = pivot.groupby(encs)[mean_vals].cumsum() - pivot[mean_vals]\n",
    "        enc = enc[vals['mean']].div(enc[_(vals['mean'])].values)\n",
    "        df = df.join(enc, how='left', on=[block, *encs], rsuffix=('_'.join(['_mean', *encs])))\n",
    "    if 'max' in vals:\n",
    "        enc = pivot.groupby(encs)[vals['max']].cummax().reset_index()\n",
    "        enc[block] += 1\n",
    "        df = df.merge(enc, how='left', on=[block, *encs], suffixes=('', '_'.join(['_max', *encs])))\n",
    "    return df\n",
    "\n",
    "for enc_cols in (['shop_id', 'item_category_id'], ['shop_id', 'item_id'], ['shop_id'], ['item_id']):\n",
    "    print('encoding:', enc_cols)\n",
    "    df = encode(df, BLOCK, enc_cols, {'mean': VAL_COLS, 'max': ['item_cnt_month']})\n",
    "\n",
    "df = proc(df)\n",
    "df.to_pickle(os.path.join(DUMP_DIR, 'data.pkl'))\n",
    "describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT THE MODEL\n",
    "df = proc(pd.read_pickle(os.path.join(DUMP_DIR, 'data.pkl')))\n",
    "features = df.columns.difference([*INDEX_COLS, *VAL_COLS, *DROP_COLS])\n",
    "\n",
    "train_val_mask = df[BLOCK].between(12, 33)\n",
    "train, val = train_test_split(df[train_val_mask], test_size=0.05, stratify=df[train_val_mask][target])\n",
    "Train = xgb.DMatrix(train[features], train[target])\n",
    "Val = xgb.DMatrix(val[features], val[target])\n",
    "\n",
    "params = {'booster': 'gbtree', #'gbtree',\n",
    "          'eta': .1,\n",
    "          'min_child_weight': 100,\n",
    "          'max_depth': 6,\n",
    "          'objective': 'reg:linear',\n",
    "          'eval_metric': 'rmse',\n",
    "          'silent': True,\n",
    "          'nthread': 4}\n",
    "model = xgb.train(params, Train, 1000, [(Train, 'Train'), (Val, 'val')], \n",
    "                  verbose_eval=10, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SUBMITION\n",
    "test = df[df[BLOCK] == 34].copy()\n",
    "test['item_cnt_month'] = model.predict(xgb.DMatrix(test[features]))\n",
    "test[['ID', 'item_cnt_month']].sort_values('ID').to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
